–°–æ–∑–¥–∞–º –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–π LLM, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª—è MacBook M3 Pro. –ë—É–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Llama.cpp —Å –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏.

## –ü–æ–ª–Ω—ã–π –∫–æ–¥ —Ä–µ—à–µ–Ω–∏—è

### 1. –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª `screenplay_parser.py`:

```python
#!/usr/bin/env python3
"""
screenplay_parser.py

–°–µ—Ä–≤–∏—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –≤ excel-—Ç–∞–±–ª–∏—Ü—É.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é LLM —á–µ—Ä–µ–∑ llama-cpp-python –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö.

–ê–≤—Ç–æ—Ä: Production Pipeline Parser
–í–µ—Ä—Å–∏—è: 1.0.0
"""

import argparse
import json
import os
import re
import sys
import gc
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict, field
import logging
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
from docx import Document
from tqdm import tqdm
import numpy as np

# –ò–º–ø–æ—Ä—Ç llama-cpp
try:
    from llama_cpp import Llama
except ImportError:
    print("–û—à–∏–±–∫–∞: llama-cpp-python –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install llama-cpp-python")
    sys.exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('screenplay_parser.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# -----------------------------
#  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
# -----------------------------

class Config:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""
    # –ü—É—Ç–∏
    MODEL_PATH = "models/mistral-7b-instruct-v0.2.Q4_K_M.gguf"  # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –¥–ª—è M3 Pro
    MODEL_PARAMS = {
        'n_ctx': 2048,        # –ö–æ–Ω—Ç–µ–∫—Å—Ç (—É–º–µ–Ω—å—à–µ–Ω –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏)
        'n_batch': 512,       # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        'n_threads': 8,       # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ (–¥–ª—è M3 Pro)
        'n_gpu_layers': 1,    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Metal (GPU –Ω–∞ Mac)
        'use_mmap': True,     # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ memory mapping
        'use_mlock': False,   # –ù–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–∞–º—è—Ç—å
        'seed': 42,
        'verbose': False
    }
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    GENERATION_PARAMS = {
        'max_tokens': 512,
        'temperature': 0.3,
        'top_p': 0.95,
        'top_k': 40,
        'repeat_penalty': 1.1,
        'stop': ["</s>", "\n\n\n", "---"]
    }
    
    # –ü–∞—Ä—Å–∏–Ω–≥
    MIN_SCENE_LENGTH = 50
    MAX_SCENE_LENGTH = 5000
    BATCH_SIZE = 5  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–æ 5 —Å—Ü–µ–Ω –∑–∞ —Ä–∞–∑

# -----------------------------
#  –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
# -----------------------------

@dataclass
class SceneMetadata:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å—Ü–µ–Ω—ã"""
    scene_number: str = ""
    episode: str = ""
    scene_type: str = ""  # INT/EXT/–ò–ù–¢/–≠–ö–°–¢/–ù–ê–¢
    location: str = ""
    sublocation: str = ""
    time_of_day: str = ""
    synopsis: str = ""
    characters: List[str] = field(default_factory=list)
    extras: str = ""
    extras_count: int = 0
    props: List[str] = field(default_factory=list)
    vehicles: List[str] = field(default_factory=list)
    special_fx: List[str] = field(default_factory=list)
    costumes: List[str] = field(default_factory=list)
    makeup: List[str] = field(default_factory=list)
    stunts: bool = False
    pyrotechnics: bool = False
    special_equipment: List[str] = field(default_factory=list)
    notes: str = ""
    raw_text: str = ""
    confidence_score: float = 0.0

# -----------------------------
#  LLM Manager
# -----------------------------

class LocalLLM:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM"""
    
    def __init__(self, model_path: str = None):
        self.model_path = model_path or Config.MODEL_PATH
        self.model = None
        self._load_model()
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–æ–¥ Mac M3"""
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {self.model_path}")
            logger.info("–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 1-2 –º–∏–Ω—É—Ç—ã...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏
            if not Path(self.model_path).exists():
                raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è M3 Pro
            self.model = Llama(
                model_path=self.model_path,
                **Config.MODEL_PARAMS
            )
            
            logger.info("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            logger.info("–†–∞–±–æ—Ç–∞–µ–º –±–µ–∑ LLM, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª–∞")
            self.model = None
    
    def generate(self, prompt: str, system_prompt: str = None) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–æ–º–ø—Ç"""
        if self.model is None:
            return "{}"
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            if system_prompt:
                full_prompt = f"<s>[INST] {system_prompt}\n\n{prompt} [/INST]"
            else:
                full_prompt = f"<s>[INST] {prompt} [/INST]"
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
            response = self.model(
                full_prompt,
                **Config.GENERATION_PARAMS
            )
            
            return response['choices'][0]['text'].strip()
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return "{}"
    
    def extract_json(self, text: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏"""
        try:
            # –ò—â–µ–º JSON –≤ —Ç–µ–∫—Å—Ç–µ
            json_match = re.search(r'\{[^}]*\}', text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º common issues
                json_str = json_str.replace("'", '"')
                json_str = re.sub(r',\s*}', '}', json_str)
                json_str = re.sub(r',\s*]', ']', json_str)
                return json.loads(json_str)
        except:
            pass
        return {}
    
    def __del__(self):
        """–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
        if self.model:
            del self.model
            gc.collect()

# -----------------------------
#  –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ü–µ–Ω–∞—Ä–∏—è
# -----------------------------

class ScenarioParser:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ü–µ–Ω–∞—Ä–∏—è"""
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    SCENE_PATTERNS = {
        'heading': re.compile(
            r'^(?P<number>\d+[-.]?\d*\.?)?\s*'
            r'(?P<type>INT\.|EXT\.|–ò–ù–¢\.|–≠–ö–°–¢\.|–ù–ê–¢\.)\s*'
            r'(?P<location>[^.\n]+?)(?:\.\s*(?P<sublocation>[^.\n]+?))?\s*[\.\-\s]*\s*'
            r'(?P<time>–î–ï–ù–¨|–ù–û–ß–¨|–£–¢–†–û|–í–ï–ß–ï–†|–†–ê–°–°–í–ï–¢|–ó–ê–ö–ê–¢|–î–µ–Ω—å|–ù–æ—á—å|–£—Ç—Ä–æ|–í–µ—á–µ—Ä)?',
            re.MULTILINE | re.IGNORECASE
        ),
        'character': re.compile(
            r'^([–ê-–Ø–ÅA-Z][–ê-–Ø–ÅA-Z\s\-,]{1,30})(?:\s*\([\w\s,]+\))?$',
            re.MULTILINE
        ),
        'parenthetical': re.compile(
            r'\(([^)]+)\)',
            re.MULTILINE
        )
    }
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    KEYWORDS = {
        'props': [
            '—Ç–µ–ª–µ—Ñ–æ–Ω', '–Ω–æ—É—Ç–±—É–∫', '–∫–æ–º–ø—å—é—Ç–µ—Ä', '–ø–∏—Å—å–º–æ', '–∫–Ω–∏–≥–∞', '—Å—É–º–∫–∞',
            '–∫–ª—é—á–∏', '–¥–æ–∫—É–º–µ–Ω—Ç—ã', '–æ—Ä—É–∂–∏–µ', '–Ω–æ–∂', '–ø–∏—Å—Ç–æ–ª–µ—Ç', '–¥–µ–Ω—å–≥–∏',
            '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–∫–∞–º–µ—Ä–∞', '–º–∏–∫—Ä–æ—Ñ–æ–Ω', '–Ω–∞—É—à–Ω–∏–∫–∏', '–æ—á–∫–∏', '—á–∞—Å—ã',
            '–∫–æ–ª—å—Ü–æ', '—Ü–≤–µ—Ç—ã', '–±—É—Ç—ã–ª–∫–∞', '—Å—Ç–∞–∫–∞–Ω', '–µ–¥–∞', '–Ω–∞–ø–∏—Ç–æ–∫'
        ],
        'vehicles': [
            '–º–∞—à–∏–Ω–∞', '–∞–≤—Ç–æ–º–æ–±–∏–ª—å', '–∞–≤—Ç–æ–±—É—Å', '—Ç–∞–∫—Å–∏', '–º–æ—Ç–æ—Ü–∏–∫–ª',
            '–≤–µ–ª–æ—Å–∏–ø–µ–¥', '—Å–∞–º–æ–ª–µ—Ç', '–≤–µ—Ä—Ç–æ–ª–µ—Ç', '–ø–æ–µ–∑–¥', '–∫–æ—Ä–∞–±–ª—å', '–ª–æ–¥–∫–∞'
        ],
        'effects': [
            '–≤–∑—Ä—ã–≤', '–≤—ã—Å—Ç—Ä–µ–ª', '–¥—ã–º', '–æ–≥–æ–Ω—å', '–ø–æ–∂–∞—Ä', '–∏—Å–∫—Ä—ã', '–∫—Ä–æ–≤—å',
            '—Å–ª–µ–∑—ã', '–¥–æ–∂–¥—å', '—Å–Ω–µ–≥', '—Ç—É–º–∞–Ω', '–≤–µ—Ç–µ—Ä', '–º–æ–ª–Ω–∏—è', '–≥—Ä–æ–º'
        ],
        'stunts': [
            '–¥—Ä–∞–∫–∞', '—É–¥–∞—Ä', '–ø–∞–¥–µ–Ω–∏–µ', '–ø—Ä—ã–∂–æ–∫', '–ø–æ–≥–æ–Ω—è', '–∞–≤–∞—Ä–∏—è',
            '–±–µ–≥', '–±–æ—Ä—å–±–∞', '—Ç—Ä—é–∫', '–∫–∞—Å–∫–∞–¥–µ—Ä'
        ]
    }
    
    def __init__(self, use_llm: bool = True):
        self.use_llm = use_llm
        self.llm = None
        if use_llm:
            self.llm = LocalLLM()
        self.scenes = []
        
    def parse_screenplay(self, text: str) -> List[SceneMetadata]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ü–µ–Ω–∞—Ä–∏—è"""
        logger.info("–ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ü–µ–Ω–∞—Ä–∏—è...")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ü–µ–Ω—ã
        scenes_raw = self._split_into_scenes(text)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(scenes_raw)} —Å—Ü–µ–Ω")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ü–µ–Ω—ã –±–∞—Ç—á–∞–º–∏
        batch_size = Config.BATCH_SIZE
        for i in tqdm(range(0, len(scenes_raw), batch_size), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ü–µ–Ω"):
            batch = scenes_raw[i:i + batch_size]
            
            for j, scene_text in enumerate(batch):
                scene_num = i + j + 1
                metadata = self._extract_scene_metadata(scene_text, scene_num)
                
                # –£–ª—É—á—à–∞–µ–º —Å –ø–æ–º–æ—â—å—é LLM –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
                if self.use_llm and self.llm and self.llm.model:
                    metadata = self._enhance_with_llm(metadata)
                
                self.scenes.append(metadata)
            
            # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –±–∞—Ç—á–∞
            gc.collect()
        
        return self.scenes
    
    def _split_into_scenes(self, text: str) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ü–µ–Ω—ã"""
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        
        # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ü–µ–Ω
        scenes = []
        scene_headers = list(self.SCENE_PATTERNS['heading'].finditer(text))
        
        if not scene_headers:
            logger.warning("–Ø–≤–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ü–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ")
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–∞–º —Å—Ç—Ä–æ–∫–∏
            parts = re.split(r'\n{2,}', text)
            return [p.strip() for p in parts 
                   if p and Config.MIN_SCENE_LENGTH <= len(p.strip()) <= Config.MAX_SCENE_LENGTH]
        
        for i, match in enumerate(scene_headers):
            start = match.start()
            end = scene_headers[i + 1].start() if i + 1 < len(scene_headers) else len(text)
            scene_text = text[start:end].strip()
            
            if Config.MIN_SCENE_LENGTH <= len(scene_text) <= Config.MAX_SCENE_LENGTH:
                scenes.append(scene_text)
        
        return scenes
    
    def _extract_scene_metadata(self, scene_text: str, scene_num: int) -> SceneMetadata:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ü–µ–Ω—ã"""
        metadata = SceneMetadata(
            scene_number=str(scene_num),
            raw_text=scene_text[:500]
        )
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ü–µ–Ω—ã
        header_match = self.SCENE_PATTERNS['heading'].search(scene_text)
        if header_match:
            groups = header_match.groupdict()
            metadata.scene_number = groups.get('number') or str(scene_num)
            metadata.scene_type = (groups.get('type') or 'INT').strip('.')
            metadata.location = (groups.get('location') or '').strip()
            metadata.sublocation = (groups.get('sublocation') or '').strip()
            metadata.time_of_day = groups.get('time') or '–î–ï–ù–¨'
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        metadata.characters = self._extract_characters(scene_text)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–Ω–æ–ø—Å–∏—Å
        metadata.synopsis = self._extract_synopsis(scene_text)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        text_lower = scene_text.lower()
        
        # –†–µ–∫–≤–∏–∑–∏—Ç
        metadata.props = [prop for prop in self.KEYWORDS['props'] 
                         if prop in text_lower][:10]
        
        # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç
        metadata.vehicles = [v for v in self.KEYWORDS['vehicles'] 
                           if v in text_lower][:5]
        
        # –°–ø–µ—Ü—ç—Ñ—Ñ–µ–∫—Ç—ã
        metadata.special_fx = [fx for fx in self.KEYWORDS['effects'] 
                              if fx in text_lower]
        
        # –¢—Ä—é–∫–∏
        metadata.stunts = any(stunt in text_lower for stunt in self.KEYWORDS['stunts'])
        
        # –ü–∏—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞
        metadata.pyrotechnics = any(word in text_lower for word in ['–≤–∑—Ä—ã–≤', '–æ–≥–æ–Ω—å', '–ø–æ–∂–∞—Ä', '–≤—ã—Å—Ç—Ä–µ–ª'])
        
        # –ú–∞—Å—Å–æ–≤–∫–∞ (–ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞)
        extras_match = re.search(r'(?:–º–∞—Å—Å–æ–≤–∫–∞|—Ç–æ–ª–ø–∞|–∑—Ä–∏—Ç–µ–ª–∏|–ø—Ä–æ—Ö–æ–∂–∏–µ|—Å—Ç—É–¥–µ–Ω—Ç—ã|–≥–æ—Å—Ç–∏)[\s:\-]*(\d+)?', 
                                 text_lower)
        if extras_match:
            metadata.extras = extras_match.group(0)
            if extras_match.group(1):
                metadata.extras_count = int(extras_match.group(1))
        
        return metadata
    
    def _extract_characters(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–µ–Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""
        characters = set()
        lines = text.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∏–º–µ–Ω–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            if self.SCENE_PATTERNS['character'].match(line):
                # –£–±–∏—Ä–∞–µ–º —Ä–µ–º–∞—Ä–∫–∏ –≤ —Å–∫–æ–±–∫–∞—Ö
                character = re.sub(r'\([^)]*\)', '', line).strip()
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ü–µ–Ω –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                if (character and 
                    not any(word in character.upper() for word in 
                           ['–ò–ù–¢', '–≠–ö–°–¢', '–ù–ê–¢', '–î–ï–ù–¨', '–ù–û–ß–¨', '–£–¢–†–û', '–í–ï–ß–ï–†']) and
                    len(character) > 2):
                    characters.add(character)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ
        # –ò—â–µ–º –∏–º–µ–Ω–∞ —Å –±–æ–ª—å—à–æ–π –±—É–∫–≤—ã –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤
        name_contexts = re.findall(
            r'(?:–≥–æ–≤–æ—Ä–∏—Ç|—Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç|–æ—Ç–≤–µ—á–∞–µ—Ç|–∫—Ä–∏—á–∏—Ç|—à–µ–ø—á–µ—Ç|–∑–æ–≤–µ—Ç)\s+([–ê-–Ø–Å][–∞-—è—ë]+)',
            text
        )
        characters.update(name_contexts)
        
        return sorted(list(characters))[:15]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 15 –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏
    
    def _extract_synopsis(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è"""
        lines = text.split('\n')
        synopsis_lines = []
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        start_idx = 0
        for i, line in enumerate(lines):
            if self.SCENE_PATTERNS['heading'].match(line):
                start_idx = i + 1
                break
        
        # –°–æ–±–∏—Ä–∞–µ–º –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        for line in lines[start_idx:]:
            line = line.strip()
            
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –Ω–∞ –¥–∏–∞–ª–æ–≥–∞—Ö
            if self.SCENE_PATTERNS['character'].match(line):
                break
                
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            if line and not line.isupper():
                synopsis_lines.append(line)
                if len(' '.join(synopsis_lines)) > 300:
                    break
        
        synopsis = ' '.join(synopsis_lines)
        # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        synopsis = ' '.join(synopsis.split())
        
        return synopsis[:400]
    
    def _enhance_with_llm(self, metadata: SceneMetadata) -> SceneMetadata:
        """–£–ª—É—á—à–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é LLM"""
        if not self.llm or not self.llm.model:
            return metadata
        
        try:
            system_prompt = """–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Ä–µ–∂–∏—Å—Å–µ—Ä–∞, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π —Å—Ü–µ–Ω–∞—Ä–∏–∏ –¥–ª—è –∫–∏–Ω–æ–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∏–∑–≤–ª–µ—á—å —Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö —Å—Ü–µ–Ω—ã.
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""

            prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ü–µ–Ω—É –∏ –∏–∑–≤–ª–µ–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:

–°–¶–ï–ù–ê: {metadata.location} - {metadata.time_of_day}
–¢–ï–ö–°–¢: {metadata.raw_text}

–£–∂–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ:
- –ü–µ—Ä—Å–æ–Ω–∞–∂–∏: {', '.join(metadata.characters[:5]) if metadata.characters else '–Ω–µ –Ω–∞–π–¥–µ–Ω—ã'}
- –†–µ–∫–≤–∏–∑–∏—Ç: {', '.join(metadata.props[:5]) if metadata.props else '–Ω–µ –Ω–∞–π–¥–µ–Ω'}

–î–æ–ø–æ–ª–Ω–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "extras_description": "–æ–ø–∏—Å–∞–Ω–∏–µ –º–∞—Å—Å–æ–≤–∫–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ",
  "additional_props": ["–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π", "—Ä–µ–∫–≤–∏–∑–∏—Ç"],
  "costume_notes": ["–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏", "–∫–æ—Å—Ç—é–º–æ–≤"],
  "makeup_notes": ["—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è", "–∫ –≥—Ä–∏–º—É"],
  "special_requirements": "–æ—Å–æ–±—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å—ä–µ–º–∫–µ"
}}"""

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = self.llm.generate(prompt, system_prompt)
            
            # –ü–∞—Ä—Å–∏–º JSON
            data = self.llm.extract_json(response)
            
            if data:
                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                if 'extras_description' in data:
                    metadata.extras = str(data['extras_description'])
                    
                if 'additional_props' in data and isinstance(data['additional_props'], list):
                    metadata.props.extend(data['additional_props'])
                    metadata.props = list(set(metadata.props))[:15]
                    
                if 'costume_notes' in data and isinstance(data['costume_notes'], list):
                    metadata.costumes = data['costume_notes'][:5]
                    
                if 'makeup_notes' in data and isinstance(data['makeup_notes'], list):
                    metadata.makeup = data['makeup_notes'][:5]
                    
                if 'special_requirements' in data:
                    metadata.notes = str(data['special_requirements'])
                
                metadata.confidence_score = 0.8  # LLM-enhanced
            else:
                metadata.confidence_score = 0.5  # Rules only
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–∏–∏ —Å LLM: {e}")
            metadata.confidence_score = 0.5
        
        return metadata

# -----------------------------
#  –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
# -----------------------------

def read_docx(path: str) -> str:
    """–ß–∏—Ç–∞–µ—Ç .docx —Ñ–∞–π–ª"""
    try:
        doc = Document(path)
        paragraphs = []
        
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                if para.style.name.startswith('Heading'):
                    text = f"\n\n{text}\n"
                paragraphs.append(text)
        
        return "\n".join(paragraphs)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {path}: {e}")
        raise

# -----------------------------
#  –≠–∫—Å–ø–æ—Ä—Ç –≤ Excel
# -----------------------------

def create_production_table(scenes: List[SceneMetadata]) -> pd.DataFrame:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –¥–ª—è pre-production"""
    rows = []
    
    for scene in scenes:
        row = {
            "–°–µ—Ä–∏—è": scene.episode or "01",
            "–°—Ü–µ–Ω–∞": scene.scene_number,
            "–†–µ–∂–∏–º": scene.time_of_day,
            "–ò–Ω—Ç/–ù–∞—Ç": scene.scene_type,
            "–û–±—ä–µ–∫—Ç": scene.location,
            "–ü–æ–¥–æ–±—ä–µ–∫—Ç": scene.sublocation,
            "–°–∏–Ω–æ–ø—Å–∏—Å": scene.synopsis[:200] if scene.synopsis else "",
            "–ü–µ—Ä—Å–æ–Ω–∞–∂–∏": ", ".join(scene.characters[:8]) if scene.characters else "",
            "–ú–∞—Å—Å–æ–≤–∫–∞": scene.extras,
            "–ö–æ–ª-–≤–æ –º–∞—Å—Å–æ–≤–∫–∏": scene.extras_count if scene.extras_count else "",
            "–†–µ–∫–≤–∏–∑–∏—Ç": ", ".join(scene.props[:8]) if scene.props else "",
            "–ò–≥—Ä–æ–≤–æ–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç": ", ".join(scene.vehicles) if scene.vehicles else "",
            "–•—É–¥–æ–∂–Ω–∏–∫–∏": "",  # –ó–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é
            "–ì—Ä–∏–º": ", ".join(scene.makeup) if scene.makeup else "",
            "–ö–æ—Å—Ç—é–º": ", ".join(scene.costumes) if scene.costumes else "",
            "–ö–∞—Å–∫–∞–¥–µ—Ä—ã": "–î–∞" if scene.stunts else "",
            "–ü–∏—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞": "–î–∞" if scene.pyrotechnics else "",
            "–°–ø–µ—Ü. –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ": ", ".join(scene.special_equipment) if scene.special_equipment else "",
            "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ": scene.notes,
            "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å": f"{scene.confidence_score:.0%}" if scene.confidence_score > 0 else ""
        }
        rows.append(row)
    
    df = pd.DataFrame(rows)
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ü–µ–Ω—ã
    try:
        df['scene_num'] = df['–°—Ü–µ–Ω–∞'].str.extract(r'(\d+)').astype(float)
        df = df.sort_values('scene_num').drop('scene_num', axis=1)
    except:
        pass
    
    return df

def export_to_excel(df: pd.DataFrame, output_path: str):
    """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç DataFrame –≤ Excel —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    try:
        from openpyxl import Workbook
        from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
        from openpyxl.utils.dataframe import dataframe_to_rows
        
        # –°–æ–∑–¥–∞–µ–º workbook
        wb = Workbook()
        ws = wb.active
        ws.title = "–ö–ü–ü"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        ws.append([f"–ö–ü–ü - –ö–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ-–ø–æ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω—ã–π –ø–ª–∞–Ω"])
        ws.merge_cells('A1:T1')
        
        # –°—Ç–∏–ª—å –∑–∞–≥–æ–ª–æ–≤–∫–∞
        header_font = Font(bold=True, size=14)
        ws['A1'].font = header_font
        ws['A1'].alignment = Alignment(horizontal='center')
        
        # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        ws.append([])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        for r in dataframe_to_rows(df, index=False, header=True):
            ws.append(r)
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å—Ç–æ–ª–±—Ü–æ–≤
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF")
        
        for cell in ws[3]:  # –¢—Ä–µ—Ç—å—è —Å—Ç—Ä–æ–∫–∞ - –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤
        column_widths = {
            'A': 8,   # –°–µ—Ä–∏—è
            'B': 10,  # –°—Ü–µ–Ω–∞
            'C': 10,  # –†–µ–∂–∏–º
            'D': 12,  # –ò–Ω—Ç/–ù–∞—Ç
            'E': 25,  # –û–±—ä–µ–∫—Ç
            'F': 25,  # –ü–æ–¥–æ–±—ä–µ–∫—Ç
            'G': 40,  # –°–∏–Ω–æ–ø—Å–∏—Å
            'H': 30,  # –ü–µ—Ä—Å–æ–Ω–∞–∂–∏
            'I': 20,  # –ú–∞—Å—Å–æ–≤–∫–∞
            'J': 10,  # –ö–æ–ª-–≤–æ
            'K': 30,  # –†–µ–∫–≤–∏–∑–∏—Ç
            'L': 20,  # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç
            'M': 20,  # –•—É–¥–æ–∂–Ω–∏–∫–∏
            'N': 20,  # –ì—Ä–∏–º
            'O': 20,  # –ö–æ—Å—Ç—é–º
            'P': 12,  # –ö–∞—Å–∫–∞–¥–µ—Ä—ã
            'Q': 12,  # –ü–∏—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞
            'R': 25,  # –°–ø–µ—Ü. –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ
            'S': 30,  # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ
            'T': 12   # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        }
        
        for col, width in column_widths.items():
            ws.column_dimensions[col].width = width
        
        # –ì—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –≤—Å–µ—Ö —è—á–µ–µ–∫ —Å –¥–∞–Ω–Ω—ã–º–∏
        thin_border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        for row in ws.iter_rows(min_row=3, max_row=ws.max_row):
            for cell in row:
                cell.border = thin_border
                cell.alignment = Alignment(vertical='top', wrap_text=True)
        
        # –£—Å–ª–æ–≤–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        for row in ws.iter_rows(min_row=4, max_row=ws.max_row, min_col=20, max_col=20):
            for cell in row:
                if cell.value:
                    try:
                        confidence = float(cell.value.strip('%')) / 100
                        if confidence >= 0.8:
                            cell.fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
                        elif confidence >= 0.6:
                            cell.fill = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")
                        else:
                            cell.fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
                    except:
                        pass
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        wb.save(output_path)
        logger.info(f"–¢–∞–±–ª–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ {output_path}")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –≤ Excel: {e}")
        # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π —ç–∫—Å–ø–æ—Ä—Ç pandas
        df.to_excel(output_path, index=False, sheet_name='–ö–ü–ü')
        logger.info(f"–¢–∞–±–ª–∏—Ü–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")

# -----------------------------
#  –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –æ—Ç—á–µ—Ç—ã
# -----------------------------

def print_statistics(scenes: List[SceneMetadata], df: pd.DataFrame):
    """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å—Ü–µ–Ω–∞—Ä–∏—é"""
    print("\n" + "="*70)
    print(" " * 20 + "–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê")
    print("="*70)
    
    # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –û–°–ù–û–í–ù–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Å—Ü–µ–Ω: {len(scenes)}")
    print(f"  ‚Ä¢ –ò–Ω—Ç–µ—Ä—å–µ—Ä—ã: {sum(1 for s in scenes if s.scene_type in ['INT', '–ò–ù–¢'])}")
    print(f"  ‚Ä¢ –ù–∞—Ç—É—Ä–∞: {sum(1 for s in scenes if s.scene_type in ['EXT', '–≠–ö–°–¢', '–ù–ê–¢'])}")
    print(f"  ‚Ä¢ –î–Ω–µ–≤–Ω—ã–µ —Å—Ü–µ–Ω—ã: {sum(1 for s in scenes if '–î–ï–ù–¨' in s.time_of_day.upper())}")
    print(f"  ‚Ä¢ –ù–æ—á–Ω—ã–µ —Å—Ü–µ–Ω—ã: {sum(1 for s in scenes if '–ù–û–ß–¨' in s.time_of_day.upper())}")
    
    # –õ–æ–∫–∞—Ü–∏–∏
    locations = df['–û–±—ä–µ–∫—Ç'].value_counts()
    print(f"\nüìç –õ–û–ö–ê–¶–ò–ò:")
    print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–æ–∫–∞—Ü–∏–π: {len(locations)}")
    print(f"  ‚Ä¢ –¢–æ–ø-5 –ª–æ–∫–∞—Ü–∏–π:")
    for loc, count in locations.head(5).items():
        print(f"    - {loc}: {count} —Å—Ü–µ–Ω")
    
    # –ü–µ—Ä—Å–æ–Ω–∞–∂–∏
    all_characters = []
    for scene in scenes:
        all_characters.extend(scene.characters)
    unique_chars = list(set(all_characters))
    
    print(f"\nüë• –ü–ï–†–°–û–ù–ê–ñ–ò:")
    print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(unique_chars)}")
    if unique_chars:
        from collections import Counter
        char_counts = Counter(all_characters)
        print(f"  ‚Ä¢ –¢–æ–ø-5 –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π:")
        for char, count in char_counts.most_common(5):
            print(f"    - {char}: {count} —Å—Ü–µ–Ω")
    
    # –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
    print(f"\nüé¨ –ü–†–û–ò–ó–í–û–î–°–¢–í–ï–ù–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:")
    print(f"  ‚Ä¢ –°—Ü–µ–Ω—ã —Å –º–∞—Å—Å–æ–≤–∫–æ–π: {sum(1 for s in scenes if s.extras)}")
    print(f"  ‚Ä¢ –°—Ü–µ–Ω—ã —Å —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–æ–º: {sum(1 for s in scenes if s.vehicles)}")
    print(f"  ‚Ä¢ –°—Ü–µ–Ω—ã —Å–æ —Å–ø–µ—Ü—ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏: {sum(1 for s in scenes if s.special_fx)}")
    print(f"  ‚Ä¢ –°—Ü–µ–Ω—ã —Å —Ç—Ä—é–∫–∞–º–∏: {sum(1 for s in scenes if s.stunts)}")
    print(f"  ‚Ä¢ –°—Ü–µ–Ω—ã —Å –ø–∏—Ä–æ—Ç–µ—Ö–Ω–∏–∫–æ–π: {sum(1 for s in scenes if s.pyrotechnics)}")
    
    # –ö–∞—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
    if any(s.confidence_score > 0 for s in scenes):
        avg_confidence = np.mean([s.confidence_score for s in scenes if s.confidence_score > 0])
        print(f"\nüìà –ö–ê–ß–ï–°–¢–í–û –ü–ê–†–°–ò–ù–ì–ê:")
        print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.0%}")
        print(f"  ‚Ä¢ –°—Ü–µ–Ω—ã —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (>80%): {sum(1 for s in scenes if s.confidence_score > 0.8)}")
        print(f"  ‚Ä¢ –°—Ü–µ–Ω—ã —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (<60%): {sum(1 for s in scenes if 0 < s.confidence_score < 0.6)}")
    
    print("\n" + "="*70)

# -----------------------------
#  –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
# -----------------------------

def main():
    parser = argparse.ArgumentParser(
        description="üé¨ –ü–∞—Ä—Å–µ—Ä —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ö–ü–ü (–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ-–ø–æ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω–æ–≥–æ –ø–ª–∞–Ω–∞)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python screenplay_parser.py -i scenario.docx -o production.xlsx
  python screenplay_parser.py -i scenario.docx --no-llm  # –±–µ–∑ LLM
  python screenplay_parser.py -i scenario.docx --model models/my_model.gguf
        """
    )
    
    parser.add_argument(
        "--input", "-i",
        required=True,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å—Ü–µ–Ω–∞—Ä–∏—è (.docx)"
    )
    parser.add_argument(
        "--output", "-o",
        default="production_table.xlsx",
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è Excel —Ç–∞–±–ª–∏—Ü—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: production_table.xlsx)"
    )
    parser.add_argument(
        "--model",
        default=Config.MODEL_PATH,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏ GGUF"
    )
    parser.add_argument(
        "--no-llm",
        action="store_true",
        help="–ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM (—Ç–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª–∞)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=Config.BATCH_SIZE,
        help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ü–µ–Ω"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="–†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤—ã–≤–æ–¥–æ–º"
    )
    
    args = parser.parse_args()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∏
    if not os.path.exists(args.input):
        logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.input}")
        sys.exit(1)
    
    if not args.input.endswith('.docx'):
        logger.error("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç .docx")
        sys.exit(1)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    Config.MODEL_PATH = args.model
    Config.BATCH_SIZE = args.batch_size
    
    try:
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        logger.info(f"üìñ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ {args.input}...")
        text = read_docx(args.input)
        logger.info(f"‚úì –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
        use_llm = not args.no_llm
        if use_llm:
            logger.info("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM...")
        else:
            logger.info("üìù –†–∞–±–æ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ –±–µ–∑ LLM (—Ç–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª–∞)")
        
        parser_obj = ScenarioParser(use_llm=use_llm)
        
        # –ü–∞—Ä—Å–∏–º —Å—Ü–µ–Ω–∞—Ä–∏–π
        scenes = parser_obj.parse_screenplay(text)
        logger.info(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ü–µ–Ω: {len(scenes)}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
        logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã production...")
        df = create_production_table(scenes)
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ {args.output}...")
        export_to_excel(df, args.output)
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print_statistics(scenes, df)
        
        print(f"\n‚úÖ –ì–û–¢–û–í–û! –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {args.output}")
        print(f"üìÇ –û—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª –≤ Excel –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(0)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        if args.debug:
            import traceback
            traceback.print_exc()
        sys.exit(1)
    finally:
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        gc.collect()

if __name__ == "__main__":
    main()
```

### 2. –§–∞–π–ª —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π `requirements.txt`:

```txt
# –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
pandas>=2.0.0
openpyxl>=3.1.0
python-docx>=0.8.11
tqdm>=4.65.0
numpy>=1.24.0

# LLM
llama-cpp-python>=0.2.20

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
XlsxWriter>=3.1.0
```

### 3. –°–∫—Ä–∏–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏ `setup_model.sh`:

```bash
#!/bin/bash
# setup_model.sh - –°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏

echo "üöÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–∞—Ä—Å–µ—Ä–∞ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤"
echo "============================================"

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
echo "üìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫..."
mkdir -p models
mkdir -p output
mkdir -p logs
mkdir -p input

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
MODEL_URL="https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf"
MODEL_PATH="models/mistral-7b-instruct-v0.2.Q4_K_M.gguf"

if [ ! -f "$MODEL_PATH" ]; then
    echo "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Mistral 7B (—ç—Ç–æ –∑–∞–π–º–µ—Ç –≤—Ä–µ–º—è, —Ä–∞–∑–º–µ—Ä ~4GB)..."
    curl -L -o "$MODEL_PATH" "$MODEL_URL"
    echo "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!"
else
    echo "‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
fi

echo ""
echo "‚ú® –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"
echo "–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä—Å–µ—Ä:"
echo "python screenplay_parser.py -i input/scenario.docx -o output/production.xlsx"
```

## üìã –ü–û–õ–ù–´–ô –ü–ê–ô–ü–õ–ê–ô–ù –£–°–¢–ê–ù–û–í–ö–ò –ò –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø

### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã

```bash
# 1.1 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Homebrew (–µ—Å–ª–∏ –µ—â–µ –Ω–µ—Ç)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# 1.2 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python 3.11 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
brew install python@3.11

# 1.3 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ cmake (–Ω—É–∂–Ω–æ –¥–ª—è llama-cpp)
brew install cmake
```

### –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞

```bash
# 2.1 –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞
mkdir screenplay_parser_project
cd screenplay_parser_project

# 2.2 –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python3.11 -m venv venv

# 2.3 –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
source venv/bin/activate
```

### –®–∞–≥ 3: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# 3.1 –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ pip
pip install --upgrade pip

# 3.2 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ llama-cpp-python —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Metal (GPU –Ω–∞ Mac)
CMAKE_ARGS="-DLLAMA_METAL=on" pip install llama-cpp-python

# 3.3 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install pandas openpyxl python-docx tqdm numpy XlsxWriter
```

### –®–∞–≥ 4: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∞–π–ª–æ–≤

```bash
# 4.1 –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª screenplay_parser.py –∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–æ–¥ –≤—ã—à–µ

# 4.2 –°–æ–∑–¥–∞–π—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
mkdir -p models output logs input

# 4.3 –°–¥–µ–ª–∞–π—Ç–µ —Å–∫—Ä–∏–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º
chmod +x setup_model.sh
```

### –®–∞–≥ 5: –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏

```bash
# –í–∞—Ä–∏–∞–Ω—Ç 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
./setup_model.sh

# –í–∞—Ä–∏–∞–Ω—Ç 2: –†—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –±–æ–ª–µ–µ –ª–µ–≥–∫–æ–π –º–æ–¥–µ–ª–∏ (2.5GB)
curl -L -o models/mistral-7b-instruct-v0.2.Q4_K_M.gguf \
  https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf
```

### –®–∞–≥ 6: –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞

```bash
# 6.1 –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫ —Å LLM
python screenplay_parser.py -i input/scenario.docx -o output/production.xlsx

# 6.2 –ë–µ–∑ LLM (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ)
python screenplay_parser.py -i input/scenario.docx -o output/production.xlsx --no-llm

# 6.3 –° –æ—Ç–ª–∞–¥–∫–æ–π
python screenplay_parser.py -i input/scenario.docx -o output/production.xlsx --debug

# 6.4 –° –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –±–∞—Ç—á–∞–º–∏ (–º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏)
python screenplay_parser.py -i input/scenario.docx --batch-size 3
```

## üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –î–õ–Ø MAC M3 PRO

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É:

1. **–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è (2GB)** - –¥–ª—è 8GB RAM:
```bash
curl -L -o models/model.gguf \
  https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
```

2. **–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è (4GB)** - –¥–ª—è 16GB RAM:
```bash
curl -L -o models/model.gguf \
  https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf
```

3. **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è (5.5GB)** - –¥–ª—è 32GB+ RAM:
```bash
curl -L -o models/model.gguf \
  https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q5_K_M.gguf
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
top -l 1 | grep PhysMem

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ GPU
sudo powermetrics --samplers gpu_power -i1000 -n1
```

## üìä –ü–†–û–í–ï–†–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í

–ü–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ:

1. **Excel —Ñ–∞–π–ª** —Å —Ç–∞–±–ª–∏—Ü–µ–π –ö–ü–ü
2. **–õ–æ–≥ —Ñ–∞–π–ª** `screenplay_parser.log`
3. **–ö–æ–Ω—Å–æ–ª—å–Ω—ã–π –≤—ã–≤–æ–¥** —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ö–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã:
- –°–µ—Ä–∏—è/–≠–ø–∏–∑–æ–¥
- –ù–æ–º–µ—Ä —Å—Ü–µ–Ω—ã
- –í—Ä–µ–º—è —Å—É—Ç–æ–∫
- –ò–Ω—Ç–µ—Ä—å–µ—Ä/–ù–∞—Ç—É—Ä–∞
- –õ–æ–∫–∞—Ü–∏—è –∏ –ø–æ–¥–ª–æ–∫–∞—Ü–∏—è
- –°–∏–Ω–æ–ø—Å–∏—Å –¥–µ–π—Å—Ç–≤–∏—è
- –°–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
- –ú–∞—Å—Å–æ–≤–∫–∞ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º
- –†–µ–∫–≤–∏–∑–∏—Ç
- –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç
- –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≥—Ä–∏–º—É/–∫–æ—Å—Ç—é–º–∞–º
- –°–ø–µ—Ü—ç—Ñ—Ñ–µ–∫—Ç—ã –∏ —Ç—Ä—é–∫–∏
- –ü—Ä–∏–º–µ—á–∞–Ω–∏—è
- –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞

## üîß –†–ï–®–ï–ù–ò–ï –ü–†–û–ë–õ–ï–ú

### –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è:
```bash
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∂–∏–º –±–µ–∑ LLM
python screenplay_parser.py -i input.docx --no-llm
```

### –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏:
```bash
# –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
python screenplay_parser.py -i input.docx --batch-size 1
```

### –ï—Å–ª–∏ Metal –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:
```bash
# –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–µ–∑ Metal
pip uninstall llama-cpp-python
pip install llama-cpp-python
```

## ‚úÖ –ì–û–¢–û–í–û!

–¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—á–∏–π –ø–∞—Ä—Å–µ—Ä —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π LLM, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª—è MacBook M3 Pro!