# Руководство по отладке проблем с пустыми результатами

## Проблема: Excel файл содержит только номера сцен, остальные колонки пустые

### Симптомы
- В логах: `WARNING - Сцена X: получен список вместо словаря`
- Excel файл содержит только колонку "Номер сцены", остальные пустые
- Модель обрабатывает все сцены, но не извлекает данные

### Причина
LLM модель возвращает JSON-массив `[...]` вместо JSON-объекта `{...}`, что приводит к игнорированию результата.

### Диагностика

#### 1. Проверьте логи
```bash
# Запустите с уровнем DEBUG для детальных логов
python -m app.main --debug
```

Ищите в логах:
- `"Сцена X - ответ модели: ..."` - показывает что именно вернула модель
- `"получен список вместо словаря"` - подтверждает проблему
- `"Модель вернула массив вместо объекта"` - детальное предупреждение

#### 2. Проверьте формат промпта
Убедитесь, что в [`app/llm_engine.py:264-362`](app/llm_engine.py:264) используется упрощенный промпт:

```python
system_prompt = """Ты - ассистент для анализа киносценариев. 
Извлекай информацию из сцен и возвращай ТОЛЬКО валидный JSON-объект."""

user_prompt = f"""Проанализируй сцену и верни JSON-объект с данными.
СЦЕНА №{scene_number}:
{scene_text}

Верни JSON в таком формате:
{json.dumps(json_schema, ensure_ascii=False, indent=2)}

Верни ТОЛЬКО JSON-объект, без дополнительного текста:"""
```

### Решения

#### Решение 1: Упрощенный промпт (уже применено)
Текущая версия использует максимально простой промпт, который явно требует JSON-объект.

#### Решение 2: Добавить явный пример в промпт
Если проблема сохраняется, добавьте конкретный пример в промпт:

```python
user_prompt = f"""Проанализируй сцену и верни JSON-объект.

ПРИМЕР ПРАВИЛЬНОГО ОТВЕТА:
{{
  "location": "Офис",
  "time_of_day": "День",
  "characters": ["Иван", "Мария"]
}}

СЦЕНА №{scene_number}:
{scene_text}

Верни JSON-объект:"""
```

#### Решение 3: Использовать constrained generation
Если модель поддерживает, можно принудительно задать JSON-схему:

```python
# В config.yaml добавить:
llm:
  generation:
    guided_json: true
    json_schema: {...}
```

#### Решение 4: Попробовать другую модель
Если Qwen2.5-14B не справляется, попробуйте:

1. **Mistral-7B-Instruct-v0.3** (лучше следует инструкциям):
```yaml
llm:
  model_name: "mistralai/Mistral-7B-Instruct-v0.3"
```

2. **Llama-3.1-8B-Instruct** (хорошо работает с JSON):
```yaml
llm:
  model_name: "meta-llama/Llama-3.1-8B-Instruct"
```

#### Решение 5: Post-processing конвертация
Добавить обработку списков в [`app/llm_engine.py:684-696`](app/llm_engine.py:684):

```python
if isinstance(entities, list):
    # Попытка конвертировать список в объект
    if len(entities) > 0 and isinstance(entities[0], dict):
        entities = entities[0]  # Берем первый элемент
    else:
        logger.warning(f"Сцена {scene.scene_number}: не удалось конвертировать список")
        entities = {}
```

### Проверка результата

После применения исправлений:

1. Запустите обработку тестового файла:
```bash
python -m app.main Examples/scenario.docx --preset basic
```

2. Проверьте логи - не должно быть предупреждений о списках

3. Откройте `output/result.xlsx` - все колонки должны быть заполнены

4. Если проблема сохраняется, включите DEBUG логирование и отправьте логи

### Дополнительная диагностика

#### Проверка формата промпта для Qwen
Убедитесь, что используется правильный формат в [`app/llm_engine.py:216-232`](app/llm_engine.py:216):

```python
if 'qwen' in model_name:
    return f"<|im_start|>system\n{system_prompt}<|im_end|>\n<|im_start|>user\n{user_prompt}<|im_end|>\n<|im_start|>assistant\n"
```

#### Проверка параметров генерации
В [`config.yaml`](config.yaml) должны быть консервативные параметры:

```yaml
llm:
  generation:
    max_new_tokens: 512
    temperature: 0.05  # Низкая температура для детерминизма
    top_p: 0.9
    repetition_penalty: 1.1
```

### Контакты для поддержки
Если проблема не решается, создайте issue с:
- Полными логами (с уровнем DEBUG)
- Примером сцены, которая не обрабатывается
- Версией модели и параметрами из config.yaml